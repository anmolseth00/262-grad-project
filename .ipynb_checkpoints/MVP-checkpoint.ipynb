{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de09604-8102-47af-aa0f-49885f3e41f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.16.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.16.1-py3-none-any.whl (266 kB)\n",
      "   ---------------------------------------- 0.0/266.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 266.9/266.9 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB ? eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: requests in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai\n",
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c39b2f-0005-4f02-a729-c0a7b80c603f",
   "metadata": {},
   "source": [
    "- This is the MVP / proof of concept\n",
    "- Using gpt-3.5-turbo because it's the cheapest\n",
    "\n",
    "To Do:\n",
    "- The current approach is basic. Some prompt engineering could be helpful. Use OAI Playground Compare to do this\n",
    "    - Need to refine enhance_query_with_openai so it's more helpful and elaborate. The current queries being constructed are trivial\n",
    "    - suggest_research_direction() needs to be split up into a few functions, and should probably make its own arxiv calls based on user_feedback and research_interests. \n",
    "    - incorporate RAG \n",
    "- Port over to langchain to build a more conversational app\n",
    "- Have a more stable way of inserting the user's API key\n",
    "- A front end would be nice. Maybe GitHub pages for a basic UI? Try to find a template online?\n",
    "- Connect to medrxiv and/or biorxiv? Building a routing system to direct API calls to the most appropriate pre-print server shouldn't be too hard.\n",
    "    - Bug: It will generate answers to biological or medical questions without even trying to find any relevant literature to back up its answers. It doesn't know which questions are out of scope. Hallucinations could be an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ae07b6e-a277-48e2-add3-fd9a7e995092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0599e593-4503-4e2f-b7c8-d75c9b915ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key here\n",
    "openai.api_key = ''\n",
    "# client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa1f5d0e-89be-472f-ad90-3b08e8231d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_query_with_openai(original_query):\n",
    "    prompt = f\"\"\"\n",
    "    Given a natural language query, convert it into a structured search query for the arXiv API. The arXiv API query format uses field prefixes like 'au' for author, 'ti' for title, 'cat' for category, and logical operators like 'AND', 'OR'. Below are examples of converting natural language queries into structured arXiv API queries:\n",
    "\n",
    "    Here are a few examples:\n",
    "    \n",
    "    Natural Language Query: Papers by Albert Einstein about relativity\n",
    "    Structured arXiv API Query: au:Albert Einstein AND all:relativity\n",
    "\n",
    "    Natural Language Query: Quantum computing research after 2015\n",
    "    Structured arXiv API Query: all:quantum computing AND submittedDate:[2015 TO *]\n",
    "\n",
    "    Natural Language Query: Machine learning applications in finance\n",
    "    Structured arXiv API Query: all:machine learning AND all:finance\n",
    "\n",
    "    Now, convert the following natural language query into a structured arXiv API query:\n",
    "    '{original_query}'\n",
    "    Structured arXiv API Query:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    # Extracting the structured query from the response\n",
    "    arxiv_query = response.choices[0].message.content.strip()\n",
    "    return arxiv_query\n",
    "\n",
    "def search_arxiv(query):\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=5'\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def extract_titles_and_summaries(xml_response):\n",
    "    # Regex patterns to match titles and summaries\n",
    "    title_pattern = re.compile(r'<title>(.*?)<\\/title>')\n",
    "    summary_pattern = re.compile(r'<summary>(.*?)<\\/summary>', re.DOTALL)  # re.DOTALL to match across newlines\n",
    "\n",
    "    titles = title_pattern.findall(xml_response)\n",
    "    summaries = summary_pattern.findall(xml_response)\n",
    "\n",
    "    # The first 'title' match is always \"ArXiv Query: ...\" so we skip it\n",
    "    titles = titles[1:]\n",
    "\n",
    "    # Pairing titles with summaries\n",
    "    papers_info = [{\"title\": title, \"summary\": summary.strip()} for title, summary in zip(titles, summaries)]\n",
    "\n",
    "    return papers_info\n",
    "\n",
    "def summarize_with_openai(initial_query, papers_info):\n",
    "    prompt = f\"The user asked: '{initial_query}'. Based on the following titles and summaries from academic papers, provide a detailed and accessible explanation of the topic:\\n\\n\"\n",
    "    \n",
    "    for paper in papers_info:\n",
    "        prompt += f\"Title: {paper['title']}\\nSummary: {paper['summary']}\\n\\n\"\n",
    "    \n",
    "    prompt += \"Please review the titles and summaries to provide a thoughtful response to the user's question.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    thoughtful_response = response.choices[0].message.content.strip()\n",
    "    return thoughtful_response\n",
    "\n",
    "def suggest_research_directions(initial_query, thoughtful_response):\n",
    "    \"\"\"\n",
    "    Generates novel research directions based on the user's feedback on a provided summary\n",
    "    and their specific interests.\n",
    "\n",
    "    Parameters:\n",
    "    - initial_query: The original query posed by the user.\n",
    "    - thoughtful_response: A comprehensive response to the initial query, summarizing relevant\n",
    "      academic papers and insights.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing suggestions for research trends, gaps, next steps, or future directions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n--- Research Direction Suggestion ---\")\n",
    "    user_feedback = input(\"What are your thoughts on the provided summary? Any specific areas of interest or questions that arise? \")\n",
    "\n",
    "    research_interests = input(\"Could you specify any particular research interests or areas where you're seeking innovation? \")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the initial inquiry about '{initial_query}' and the provided summary, the researcher shared their thoughts: '{user_feedback}'. They expressed a particular interest in '{research_interests}'.\n",
    "\n",
    "    Considering the current state of research and potential future developments, identify emerging trends, and gaps in the literature, and suggest novel research directions or next steps that could significantly advance the field. Emphasize novelty and innovation in your suggestions.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    research_suggestions = response.choices[0].message.content.strip()\n",
    "    return research_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3854c3ac-9324-4270-86eb-88cbe33d87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  Latest advancements in CRISPR and gene editing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting your query into an arXiv-friendly format...\n",
      "Here is the arXiv Query I am using: all:\"CRISPR AND gene editing\" AND sortBy:submittedDate\n",
      "Fetching papers from arXiv...\n",
      "Here's what I found:\n",
      " Title: \"Prime editing: precision genome editing by reverse transcription\"\n",
      "Summary: Prime editing is a new type of genome editing tool that allows for precise changes to the DNA sequence of an organism without the need for double-strand breaks, making it potentially safer and more efficient than previous gene editing techniques.\n",
      "\n",
      "Title: \"Cytosine base editors with minimized unguided DNA and RNA off-target events and high on-target activity\"\n",
      "Summary: Cytosine base editors are a type of gene editing tool that can change individual DNA bases in a highly targeted manner. This research focuses on improving the precision and reducing off-target effects of these base editors, making them more effective and safer for use in research and potential therapeutic applications.\n",
      "\n",
      "Title: \"CRISPR-Cas12a target binding unleashes indiscriminate single-stranded DNase activity\"\n",
      "Summary: This study highlights a new functionality of the CRISPR-Cas12a system, which is a type of gene-editing tool. It has the ability to not only target specific DNA sequences for editing but also exhibits single-stranded DNase activity, meaning it can break down single-stranded DNA in a non-specific manner, broadening its utility in genome editing applications.\n",
      "\n",
      "CRISPR (clustered regularly interspaced short palindromic repeats) technology has revolutionized the field of genetic engineering and gene editing by providing a precise and efficient way to make changes to the DNA of living organisms. One of the latest advancements in CRISPR technology is prime editing, which allows for highly precise genome editing without the need for creating double-strand breaks in the DNA. Prime editing combines a modified version of the CRISPR-Cas9 system with a reverse transcriptase enzyme to directly rewrite target DNA sequences with unprecedented accuracy.\n",
      "\n",
      "Another advancement in gene editing is the development of cytosine base editors, which enable specific changes to individual DNA bases without completely cutting the DNA strands. Scientists are continually refining these base editors to increase their precision and minimize off-target effects, making them more dependable tools for genetic research and potential therapeutic interventions.\n",
      "\n",
      "Furthermore, research into CRISPR-Cas12a has revealed its additional ability to act as a single-stranded DNase enzyme, allowing it to cleave single-stranded DNA sequences in a non-specific manner. This newfound functionality expands the utility of CRISPR-Cas12a in genome editing applications and opens up new possibilities for manipulating DNA sequences with greater versatility.\n",
      "\n",
      "In summary, these recent advancements in CRISPR and gene editing technologies, such as prime editing, improved base editors, and expanded functionalities of CRISPR systems, are enhancing the precision, efficiency, and safety of genetic modifications, paving the way for novel applications in basic research, biotechnology, and potentially, therapeutic interventions.\n",
      "\n",
      "--- Research Direction Suggestion ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What are your thoughts on the provided summary? Any specific areas of interest or questions that arise?  Pretty interesting, I'm interested in prime editing.\n",
      "Could you specify any particular research interests or areas where you're seeking innovation?  Yes, I want to innovate on pegRNAs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few research ideas to inspire your work:\n",
      " Given your interest in prime editing and pegRNAs, here are some emerging trends, gaps in the literature, and potential novel research directions that could significantly advance the field:\n",
      "\n",
      "1. **Emerging Trends**:\n",
      "   - **Improving Editing Efficiency**: Researchers are actively working on enhancing the efficiency of prime editing by optimizing the components involved, such as the pegRNA design, Cas enzyme, and delivery methods.\n",
      "   - **Reducing Off-Target Effects**: Addressing off-target effects remains a critical area of focus, with advancements in developing more precise editing tools and strategies to minimize unintended genetic modifications.\n",
      "   - **Expanding Targetable Genomic Regions**: Efforts are being made to increase the scope of targetable genomic regions using prime editing, including challenging loci with high GC content or repetitive sequences.\n",
      "\n",
      "2. **Gaps in the Literature**:\n",
      "   - **Functional Characterization of pegRNAs**: While pegRNAs are essential for prime editing, there is a lack of comprehensive studies on their functionality, specificity, and efficiency across different genomic targets and cell types.\n",
      "   - **Delivery Optimization**: Research on improving the delivery efficiency of prime editing components, especially pegRNAs, into various cell types and tissues is still limited, presenting a significant gap in the literature.\n",
      "   - **Long-Term Stability and Safety**: Studies focusing on the long-term stability and safety of prime-edited cells, particularly regarding genomic integrity and potential off-target effects over extended periods, are scarce.\n",
      "\n",
      "3. **Novel Research Directions**:\n",
      "   - **PEGylation for Enhanced pegRNA Stability**: Investigate the use of PEGylation techniques to increase the stability and cellular uptake of pegRNAs, potentially improving editing efficiency and reducing off-target effects.\n",
      "   - **Multiplexing with pegRNAs**: Explore the feasibility of multiplex prime editing by designing pegRNAs that enable simultaneous editing of multiple genomic loci, providing a more efficient and versatile editing tool.\n",
      "   - **Innovative Delivery Strategies**: Develop innovative delivery strategies, such as nanoparticle-based systems or viral vectors, tailored specifically for delivering pegRNAs and prime editing components to target cells with high precision and efficiency.\n",
      "\n",
      "By delving into these novel research directions, you can contribute significantly to advancing prime editing technology, addressing current challenges, and paving the way for more precise and effective genome editing tools with diverse applications in basic research and therapeutic interventions.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    print(\"Converting your query into an arXiv-friendly format...\")\n",
    "    arxiv_query = enhance_query_with_openai(user_query)\n",
    "    print(f\"Here is the arXiv Query I am using: {arxiv_query}\\nFetching papers from arXiv...\")\n",
    "    arxiv_results = search_arxiv(arxiv_query)\n",
    "    extracted_information = extract_titles_and_summaries(arxiv_results)\n",
    "    # print(extracted_information)\n",
    "    thoughtful_response = summarize_with_openai(user_query, extracted_information)\n",
    "    print(\"Here's what I found:\\n\", thoughtful_response)\n",
    "    research_suggestions = suggest_research_directions(user_query, thoughtful_response)\n",
    "    print(\"Here are a few research ideas to inspire your work:\\n\", research_suggestions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da28b92-ae40-41df-9846-b46017f4e777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
