{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3726a1-1fa1-4f72-8380-30fea6d70fb6",
   "metadata": {},
   "source": [
    "https://pypi.org/project/arxiv/\n",
    "\n",
    "Turns out there's a python wrapper for the arXiv API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5197b943-905d-43af-8cd1-3f501738cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet arxiv\n",
    "!pip install --upgrade --quiet pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908da8a5-c347-4bd9-b741-0a52afac81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b0d0ed-3957-432a-b3ba-b40e203ba100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-field theory of 1+1D $\\mathbb{Z}_2$ lattice gauge theory with matter\n",
      "Pair production in rotating electric fields via quantum kinetic equations: Resolving helicity states\n",
      "Gaussian Process Regression with Soft Inequality and Monotonicity Constraints\n",
      "Dark energy as a geometrical effect in geodetic brane gravity\n",
      "Forecasting the sensitivity of Pulsar Timing Arrays to gravitational wave backgrounds\n",
      "Scalable quantum detector tomography by high-performance computing\n",
      "Efficient Quantum Circuits for Non-Unitary and Unitary Diagonal Operators with Space-Time-Accuracy trade-offs\n",
      "Thermodynamics and Quasinormal Modes of the Dymnikova Black Hole in Higher Dimensions\n",
      "Anyonic quantum multipartite maskers in the Kitaev model\n",
      "Dancing above the abyss: Environmental effects and dark matter signatures in inspirals into massive black holes\n",
      "['Mean-field theory of 1+1D $\\\\mathbb{Z}_2$ lattice gauge theory with matter', 'Pair production in rotating electric fields via quantum kinetic equations: Resolving helicity states', 'Gaussian Process Regression with Soft Inequality and Monotonicity Constraints', 'Dark energy as a geometrical effect in geodetic brane gravity', 'Forecasting the sensitivity of Pulsar Timing Arrays to gravitational wave backgrounds', 'Scalable quantum detector tomography by high-performance computing', 'Efficient Quantum Circuits for Non-Unitary and Unitary Diagonal Operators with Space-Time-Accuracy trade-offs', 'Thermodynamics and Quasinormal Modes of the Dymnikova Black Hole in Higher Dimensions', 'Anyonic quantum multipartite maskers in the Kitaev model', 'Dancing above the abyss: Environmental effects and dark matter signatures in inspirals into massive black holes']\n",
      "http://arxiv.org/abs/cond-mat/0603029v1\n",
      "From stripe to checkerboard order on the square lattice in the presence of quenched disorder\n"
     ]
    }
   ],
   "source": [
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "  query = \"quantum\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "# `results` is a generator; you can iterate over its elements one by one...\n",
    "for r in client.results(search):\n",
    "  print(r.title)\n",
    "# ...or exhaust it into a list. Careful: this is slow for large results sets.\n",
    "all_results = list(results)\n",
    "print([r.title for r in all_results])\n",
    "\n",
    "# For advanced query syntax documentation, see the arXiv API User Manual:\n",
    "# https://arxiv.org/help/api/user-manual#query_details\n",
    "search = arxiv.Search(query = \"au:del_maestro AND ti:checkerboard\")\n",
    "first_result = next(client.results(search))\n",
    "print(first_result)\n",
    "\n",
    "# Search for the paper with ID \"1605.08386v1\"\n",
    "search_by_id = arxiv.Search(id_list=[\"1605.08386v1\"])\n",
    "# Reuse client to fetch the paper, then print its title.\n",
    "first_result = next(client.results(search))\n",
    "print(first_result.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d68f39-dbe9-4b4c-9fba-405ffdd4057f",
   "metadata": {},
   "source": [
    "Not that impressive, we already have this functionality. But we could use this later to clean up some code I wrote earlier in MVP.ipynb\n",
    "\n",
    "Only interesting feature is the Result.download_pdf() function. Maybe we could add this feature so the user can download a preprint they find interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b006fa-4688-4923-a1da-91bf314160b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29102949-eea9-4bdb-a917-806f3189d3e0",
   "metadata": {},
   "source": [
    "Langchain is probably the best way of turning this tool 'conversational'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f04cbf6c-7b28-40e5-bec5-6d2929dca37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47384ccf-ddfd-4f2f-8531-e68924ba92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9e8af3-ee54-483d-a698-8493066ade3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ArxivLoader(query=\"quantum computing\", load_max_docs=2).load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9cb184d-6e23-4eec-8110-f68be2fbff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2022-08-01',\n",
       " 'Title': 'The Rise of Quantum Internet Computing',\n",
       " 'Authors': 'Seng W. Loke',\n",
       " 'Summary': 'This article highlights quantum Internet computing as referring to\\ndistributed quantum computing over the quantum Internet, analogous to\\n(classical) Internet computing involving (classical) distributed computing over\\nthe (classical) Internet. Relevant to quantum Internet computing would be areas\\nof study such as quantum protocols for distributed nodes using quantum\\ninformation for computations, quantum cloud computing, delegated verifiable\\nblind or private computing, non-local gates, and distributed quantum\\napplications, over Internet-scale distances.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata  # meta-information of the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2165b71b-903c-4126-a684-5b35f265d284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv:2208.00733v1  [cs.ET]  1 Aug 2022\\nIEEE IOT MAGAZINE, VOL. XX, NO. X, X 2022\\n1\\nThe Rise of Quantum Internet Computing\\nSeng W. Loke, Member, IEEE\\nAbstract—This article highlights quantum Internet computing as referring to distributed quantum computing over the quantum Internet,\\nanalogous to (classical) Internet computing involving (classical) distributed computing over the (classical) Internet. Relevant to\\nquantum Internet computing would be areas of study such as quantum protocols for distributed nodes using quantum information for\\ncomputations, quantum cloud computing, delegated veriﬁable blind or private computing, non-local gates, and distributed quantum\\napplications, over Internet-scale distances.\\nIndex Terms—quantum Internet computing, quantum Internet, distributed quantum computing, Internet computing, distributed\\nsystems, Internet\\n”This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this\\nversion may no longer be accessible.”\\n✦\\n1\\nINTRODUCTION\\nT\\nHERE have been tremendous developments in quantum\\ncomputing, quantum cryptography, quantum commu-\\nnications and the quantum Internet, and we have seen\\nincreased investments and intensive research in quantum\\ncomputing in recent years [1], [2]. The quantum Internet will\\nnot necessarily replace the (classical) Internet we know and\\nuse today, at least not in the near future, but can complement\\nthe current Internet. The quantum Internet aims to enable\\nrobust quantum teleportation (or transmission) of qubits,1\\nand entanglement among qubits,2 over long Internet-scale\\ndistances, which are key to many of the quantum protocols\\nincluding quantum key distribution, quantum voting, and\\nothers, as well as for non-local control of quantum gates.\\nThere have been efforts to build quantum computers,\\nand it remains to see if any one paradigm becomes the\\ndominant or best way of building such quantum comput-\\ners. At the same time, even as researchers develop more\\npowerful quantum computers (supporting more qubits for\\noperations, and at lower error rates), there is an opportunity\\nfor connecting multiple quantum computers from differ-\\nent sites to achieve much more complex quantum com-\\nputations, i.e., inter-linking multiple quantum computers\\non different sites to perform distributed computing with\\na distributed system of quantum computers (or quantum\\nprocessing units (QPUs) at different nodes), arriving at the\\nnotion of distributed quantum computing, e.g., [3].\\nWhile distributed quantum computing can involve mul-\\ntiple QPUs next to each other or at the same site, with the\\nquantum Internet, one can envision distributed quantum\\n•\\nSeng W. Loke is with the School of Information Technology, Deakin\\nUniversity, Melbourne, Australia.\\nE-mail: see https://www.deakin.edu.au/about-deakin/people/seng-loke.\\nManuscript received X XX, 20XX; revised X XX, 20XX.\\n1. A qubit is the basic unit of quantum information, and can be\\nthought of as a two-state, or two-levelled, quantum-mechanical system,\\nsuch as an electron’s spin, where the two levels are spin up and spin\\ndown, or a photon’s polarization, where the two states are the vertical\\npolarization and the horizontal polarization.\\n2. Multiple qubits at different sites can share an entangled state, a\\nsuperpositon of “specially correlated” states, to be used in distributed\\nalgorithms.\\ncomputing over nodes geographically far apart. As noted\\nin [4], the idea is the quantum Internet as the “underly-\\ning infrastructure of the Distributed Quantum Computing\\necosystem.”\\nThis article highlights the emerging area of distributed\\nquantum computing over the quantum Internet, which we\\nrefer to as quantum Internet computing, i.e., the idea of com-\\nputing using quantumly connected distributed quantum\\ncomputers over Internet-scale distances. Hence, quantum\\nInternet computing is not a new concept in itself but a\\nproposed “umbrella term” used here for the collection of\\ntopics (listed below), from an analogy to (classical) Internet\\ncomputing.\\nInternet computing, where one does distributed comput-\\ning but over Internet-scale distances and distributed sys-\\ntems involve nodes connected via the Internet, is at the inter-\\nsection of work in (classical) distributed computing and the\\n(classical) Internet. Analogous to Internet computing, one\\ncould ask the question of what would be at the intersection\\nof work in distributed quantum computing and work on the\\nquantum Internet, which brings us to the notion of quantum\\nInternet computing.\\nAlso, while the quantum Internet and distributed quan-\\ntum computing are still nascent research areas, there are at\\nleast three key topics which can be considered as relevant to\\nquantum Internet computing:\\n•\\ndistributed quantum computing, including quantum\\nprotocols from theoretical perspectives involving\\ncommunication complexity studies, and distributed\\nquantum computing via non-local or distributed\\nquantum gates,\\n•\\nquantum cloud computing with a focus on delegat-\\ning quantum computations, blind quantum comput-\\ning, and verifying delegated quantum computations,\\nand\\n•\\ncomputations and algorithms for the quantum Inter-\\nnet including key ideas such as quantum entangle-\\nment distillation, entanglement swapping, quantum\\nIEEE IOT MAGAZINE, VOL. XX, NO. X, X 2022\\n2\\nrepeaters, and quantum Internet standards.3\\nWe brieﬂy discuss the above topics in the following sections.\\n2\\nDISTRIBUTED QUANTUM COMPUTING\\nDistributed quantum computing problems and quantum\\nprotocols have been well-studied for over two decades,\\nfrom a theoretical computer science perspective,4 many of\\nwhich have their inspiration from classical distributed com-\\nputing research. Quantum versions of classical distributed\\ncomputing problems and protocols, and new forms of dis-\\ntributed computing using quantum information, have been\\nexplored, e.g., the distributed three-party product problem,\\nthe distributed Deutsch-Jozsa promise problem and the\\ndistributed intersection problem, demonstrating how, for\\nsome problems, quantum information can enable fewer\\nbits of communication to be used for a solution, and how\\ncertain distributed computation problems can be solved\\nwith quantum information, but cannot be solved classically.\\nMany quantum protocols, including quantum coin ﬂipping,\\nquantum leader election, quantum anonymous broadcast-\\ning, quantum voting, quantum Byzantine Generals, quan-\\ntum secret sharing, and quantum oblivious transfer, can\\nbe viewed as “quantum versions” of classical distributed\\ncomputing problems, and have been studied extensively.\\nAnother area of study, which has also been considered\\nas distributed quantum computing, is non-local gates, or\\nthe non-local control of quantum gates, including early\\nwork nearly over two decades ago.5 Key to performing\\nsuch non-local control of quantum gates is the use of en-\\ntanglement, which can be viewed as a resource for such\\nnon-local computations. More recent work has looked at\\nhow to partition the computations of distributed quantum\\ncircuits over multiple QPUs, e.g., [3] as we mentioned earlier\\n- with considerations including distributing computations\\nin such a way as to optimize performance and to reduce the\\nrequirements on entanglement, since if the entanglements\\nrequired are generated at too low a rate, this will hold up\\ncomputations. The key motivation here is to inter-link a\\nset of quantum computers to form effectively a much more\\npowerful quantum computer.\\n3\\nQUANTUM CLOUD COMPUTING AND DELEGAT-\\nING QUANTUM COMPUTATIONS\\nWe have seen big tech companies and startups offering\\nquantum computing as a service similar to accessing other\\ncloud service offerings, which is a fantastic resource for\\nexperimentation and studies.\\nMore formally, studies into delegating quantum com-\\nputation from a client (which can be either classical, or\\nalmost classical, i.e., with minimal capability to perform\\n3. For example, see https://www.ietf.org/archive/id/draft-irtf-qirg-principles-10.html\\n[last accessed: 1/8/2022]\\n4. For example, see Buhrman and R¨\\nohrig’s paper dating back to\\n2003: https://link.springer.com/chapter/10.1007/978-3-540-45138-9 1\\n[last accessed: 1/8/2022]\\n5. For example, see the work by Yimsiriwattana and Lomonaco\\nJr.\\nin\\nhttps://arxiv.org/pdf/quant-ph/0402148.pdf\\nand\\na\\ndistributed\\nversion\\nof\\nShor’s\\nfamous\\nfactorization\\nalgorithm\\nhttps://arxiv.org/abs/2207.05976 [last accessed: 1/8/2022]\\ncomputations such as teleporting qubits, applying simple\\nPauli quantum operations, and doing basic measurements)\\nwhich is much more restricted than the server (assumed\\nto be a universal quantum computer) have been studied,\\ncalled delegated quantum computing. And when the server\\nis prevented from knowing the client’s inputs but still can\\nperform delegated computations, by a technique such as\\nthe quantum one-time pad (where the client applies Pauli\\noperations to add uncertainty from the server’s perspective,\\nthereby effectively encrypting the quantum inputs it sends\\nto the server, and keeps track of operations it later needs\\nto decrypt the outputs from the server), this is called blind\\nquantum computing.\\nIn order to be sure that the server does indeed perform\\nthe required quantum operations delegated to it by the\\nclient, the client can embed tests (or test runs) into the\\ndelegated computations, so that the server (not being able\\nto distinguish between tests and normal computations) can\\nbe caught out if it did not perform the required compu-\\ntations properly. That is, the client can verify if the server\\nperformed the required quantum computations.6 Further\\nabstractions for delegating quantum computations with\\nsupporting cloud services continues to be investigated.\\n4\\nTHE QUANTUM INTERNET\\nAs we mentioned earlier, work on the quantum Internet\\nfocuses on how to efﬁciently enable robust entanglement\\nshared among qubits over long geographical distances. If\\ntwo nodes in different continents share entangled states,\\nthen, this can be a resource to do non-local gates, i.e.,\\nto perform distributed quantum compu'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:10000]  # all pages of the Document content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6576c19-4f1a-496e-bf5e-fd2ab1ecf904",
   "metadata": {},
   "source": [
    "### Turns out there's already a semantic search feature for arXiv built into langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3766a138-5c9e-4a66-a01f-ccc848d83a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# get a token: https://platform.openai.com/account/api-keys\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63ce0895-43d0-4b66-a9e5-29eb01fb5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a1c3520-9e67-4289-be46-927f6f81068a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (0.1.40)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (1.16.1)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.1.40)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.5.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.5.2->langchain_openai)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------- -------------------- 20.5/42.0 kB ? eta -:--:--\n",
      "     ----------------------------- ---------- 30.7/42.0 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 503.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anmol\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
      "Downloading tiktoken-0.6.0-cp311-cp311-win_amd64.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.7 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/798.7 kB 3.4 MB/s eta 0:00:01\n",
      "   --- ----------------------------------- 71.7/798.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 92.2/798.7 kB 751.6 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 92.2/798.7 kB 751.6 kB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 225.3/798.7 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------- -------------------------- 235.5/798.7 kB 901.1 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 286.7/798.7 kB 930.9 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 317.4/798.7 kB 893.0 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 317.4/798.7 kB 893.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 409.6/798.7 kB 881.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 430.1/798.7 kB 867.4 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 430.1/798.7 kB 867.4 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 450.6/798.7 kB 761.8 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 481.3/798.7 kB 753.7 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 481.3/798.7 kB 753.7 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 593.9/798.7 kB 811.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 624.6/798.7 kB 803.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 706.6/798.7 kB 841.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 798.7/798.7 kB 901.1 kB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/269.5 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/269.5 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 143.4/269.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/269.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.5/269.5 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken, langchain_openai\n",
      "Successfully installed langchain_openai-0.1.1 regex-2023.12.25 tiktoken-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754b8bbb-73e0-4820-bd7e-4bd214dfb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "retriever = ArxivRetriever(load_max_docs=3)\n",
    "docs = retriever.get_relevant_documents(query=\"quantum physics\")\n",
    "docs[0].metadata #meta-information\n",
    "docs[0].page_content[:400]  # a content of the Document\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")  # switch to 'gpt-4'\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d91f0bd-1096-4835-94a7-2de4d377ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anmol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What are Heat-bath random walks with Markov base? \n",
      "\n",
      "**Answer**: I don't have information on \"Heat-bath random walks with Markov base\" based on the context provided. \n",
      "\n",
      "-> **Question**: What is the ImageBind model? \n",
      "\n",
      "**Answer**: The ImageBind model is an approach that learns a joint embedding across six different modalities: images, text, audio, depth, thermal, and IMU data. It demonstrates that only image-paired data is necessary to train such a joint embedding, which binds the modalities together. ImageBind leverages large-scale vision-language models, extending their capabilities to new modalities through natural pairing with images. It enables various applications like cross-modal retrieval, composition of modalities, cross-modal detection and generation. The model sets a new state-of-the-art on zero-shot recognition tasks across modalities and showcases strong few-shot recognition results, outperforming previous work. Additionally, ImageBind serves as a new evaluation method for vision models in visual and non-visual tasks. \n",
      "\n",
      "-> **Question**: How does Compositional Reasoning with Large Language Models works? \n",
      "\n",
      "**Answer**: Compositional reasoning with large language models involves training the models to understand and reason about the compositional nature of input data. In the context of audio-language models, like CLAP, the models are trained to learn shared representations between audio and language modalities. This training allows the models to perform tasks that involve understanding the order or occurrence of acoustic events in audio (CompA-order) and attribute binding of acoustic events (CompA-attribute). By evaluating how well the model matches the right audio to the right caption in these benchmarks, researchers can assess the model's compositional reasoning capabilities. Additionally, improvements in contrastive training methods, such as using composition-aware hard negatives and modular contrastive loss, can help enhance the model's ability to learn fine-grained compositional understanding. In the case of CompA-CLAP, a specific approach is taken to fine-tune CLAP to improve its compositional reasoning abilities, leading to superior performance on the CompA benchmark. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What are Heat-bath random walks with Markov base?\",\n",
    "    \"What is the ImageBind model?\",\n",
    "    \"How does Compositional Reasoning with Large Language Models works?\",\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255e8ed-9ff0-45b8-bcc9-2527aed1782e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
