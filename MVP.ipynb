{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de09604-8102-47af-aa0f-49885f3e41f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (1.16.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: requests in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alanphlips/anaconda3/envs/262proj/lib/python3.12/site-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c39b2f-0005-4f02-a729-c0a7b80c603f",
   "metadata": {},
   "source": [
    "- This is the MVP / proof of concept\n",
    "- Using gpt-3.5-turbo because it's the cheapest\n",
    "- https://info.arxiv.org/help/api/user-manual.html#arxiv-api-users-manual\n",
    "\n",
    "To Do:\n",
    "- The current approach is basic. Some prompt engineering could be helpful. Use OAI Playground Compare to do this\n",
    "    - Need to refine enhance_query so it's more helpful and elaborate. The current queries being constructed are trivial\n",
    "    - suggest_research_direction() needs to be split up into a few functions, and should probably make its own arxiv calls based on user_feedback and research_interests. \n",
    "    - incorporate RAG \n",
    "- Port over to langchain to build a more conversational app\n",
    "- Have a more stable way of inserting the user's API key\n",
    "- A front end would be nice. Maybe GitHub pages for a basic UI? Try to find a template online? \n",
    "    #github pages apparently only serves static contact, which isnt great for us. Love the idea but sadly not viable and a more full stack is needed\n",
    "- Connect to medrxiv and/or biorxiv? Building a routing system to direct API calls to the most appropriate pre-print server shouldn't be too hard.\n",
    "    - Bug: It will generate answers to biological or medical questions without even trying to find any relevant literature to back up its answers. It doesn't know which questions are out of scope. Hallucinations could be an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae07b6e-a277-48e2-add3-fd9a7e995092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0599e593-4503-4e2f-b7c8-d75c9b915ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key here\n",
    "OpenAI.api_key = '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'\n",
    "#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\n",
    "#client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "client = OpenAI(api_key=OpenAI.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1f5d0e-89be-472f-ad90-3b08e8231d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_query(original_query):\n",
    "    prompt = f\"\"\"\n",
    "    Given a natural language query, convert it into a structured search query for the arXiv API. The arXiv API query format uses field prefixes like 'au' for author, 'ti' for title, 'cat' for category, and logical operators like 'AND', 'OR'. Below are examples of converting natural language queries into structured arXiv API queries:\n",
    "\n",
    "    Here are a few examples:\n",
    "    \n",
    "    Natural Language Query: Papers by Albert Einstein about relativity\n",
    "    Structured arXiv API Query: au:Albert Einstein AND all:relativity\n",
    "\n",
    "    Natural Language Query: Quantum computing research after 2015\n",
    "    Structured arXiv API Query: all:quantum computing AND submittedDate:[2015 TO *]\n",
    "\n",
    "    Natural Language Query: Machine learning applications in finance\n",
    "    Structured arXiv API Query: all:machine learning AND all:finance\n",
    "\n",
    "    Now, convert the following natural language query into a structured arXiv API query:\n",
    "    '{original_query}'\n",
    "    Structured arXiv API Query:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    # Extracting the structured query from the response\n",
    "    arxiv_query = response.choices[0].message.content.strip()\n",
    "    return arxiv_query\n",
    "\n",
    "def search_arxiv(query):\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=5'\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def extract_titles_and_summaries(xml_response):\n",
    "    # Regex patterns to match titles and summaries\n",
    "    title_pattern = re.compile(r'<title>(.*?)<\\/title>')\n",
    "    summary_pattern = re.compile(r'<summary>(.*?)<\\/summary>', re.DOTALL)  # re.DOTALL to match across newlines\n",
    "\n",
    "    titles = title_pattern.findall(xml_response)\n",
    "    summaries = summary_pattern.findall(xml_response)\n",
    "\n",
    "    # The first 'title' match is always \"ArXiv Query: ...\" so we skip it\n",
    "    titles = titles[1:]\n",
    "\n",
    "    # Pairing titles with summaries\n",
    "    papers_info = [{\"title\": title, \"summary\": summary.strip()} for title, summary in zip(titles, summaries)]\n",
    "\n",
    "    return papers_info\n",
    "\n",
    "def summarize(initial_query, papers_info):\n",
    "    prompt = f\"The user asked: '{initial_query}'. Based on the following titles and summaries from academic papers, provide a detailed and accessible explanation of the topic:\\n\\n\"\n",
    "    \n",
    "    for paper in papers_info:\n",
    "        prompt += f\"Title: {paper['title']}\\nSummary: {paper['summary']}\\n\\n\"\n",
    "    \n",
    "    prompt += \"Please review the titles and summaries to provide a thoughtful response to the user's question.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    thoughtful_response = response.choices[0].message.content.strip()\n",
    "    return thoughtful_response\n",
    "\n",
    "def suggest_research_directions(initial_query, thoughtful_response):\n",
    "    \"\"\"\n",
    "    Generates novel research directions based on the user's feedback on a provided summary\n",
    "    and their specific interests.\n",
    "\n",
    "    Parameters:\n",
    "    - initial_query: The original query posed by the user.\n",
    "    - thoughtful_response: A comprehensive response to the initial query, summarizing relevant\n",
    "      academic papers and insights.\n",
    "\n",
    "    Returns:\n",
    "    - A string containing suggestions for research trends, gaps, next steps, or future directions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n--- Research Direction Suggestion ---\")\n",
    "    user_feedback = input(\"What are your thoughts on the provided summary? Any specific areas of interest or questions that arise? \")\n",
    "\n",
    "    research_interests = input(\"Could you specify any particular research interests or areas where you're seeking innovation? \")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the initial inquiry about '{initial_query}' and the provided summary, the researcher shared their thoughts: '{user_feedback}'. They expressed a particular interest in '{research_interests}'.\n",
    "\n",
    "    Considering the current state of research and potential future developments, identify emerging trends, and gaps in the literature, and suggest novel research directions or next steps that could significantly advance the field. Emphasize novelty and innovation in your suggestions.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    research_suggestions = response.choices[0].message.content.strip()\n",
    "    return research_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3854c3ac-9324-4270-86eb-88cbe33d87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting your query into an arXiv-friendly format...\n",
      "Here is the arXiv Query I am using: au:John Lafferty\n",
      "Fetching papers from arXiv...\n",
      "Here's what I found:\n",
      " The papers written by John Lafferty focus on two main topics: \"Denoising Flows on Trees\" and \"Nonparametric Reduced Rank Regression.\"\n",
      "\n",
      "In the paper \"Denoising Flows on Trees,\" Lafferty extends Pinsker's theorem in statistical theory to address estimation under storage or communication constraints. The focus is on characterizing the minimax rate in nonparametric estimation while placing limits on the bits used to encode an estimator. By analyzing the excess risk concerning these constraints, signal size, and noise level, the paper establishes a Pareto-optimal minimax tradeoff between storage and risk for the case of a Euclidean ball. This work aims to provide a comprehensive understanding of the tradeoff between storage limitations and estimation accuracy in a statistical setting.\n",
      "\n",
      "In the paper \"Nonparametric Reduced Rank Regression,\" Lafferty investigates the estimation of flows on trees, which is a structured extension of isotonic regression. The concept of tree flows is introduced, where flow values are recursively defined within a tree structure. The study focuses on the behavior of the least squares estimator for flows and the associated minimax lower bounds. The paper distinguishes between two regimes based on the tree's characteristics: one where the tree diameter grows logarithmically with the number of nodes and another where the tree contains long paths. By comparing the results to known risk bounds for isotonic regression, Lafferty provides insights into the estimation of structured data beyond traditional regression techniques.\n",
      "\n",
      "In summary, John Lafferty's research delves into advanced statistical estimation techniques, extending classical theorems to address practical constraints and exploring structured estimation problems such as flows on trees. His work contributes to theoretical foundations and practical applications in nonparametric estimation and regression analysis.\n",
      "\n",
      "--- Research Direction Suggestion ---\n",
      "Here are a few research ideas to inspire your work:\n",
      " Given the interest in papers by John Lafferty and the summary provided, there are several emerging trends, potential gaps in the literature, and novel research directions worth exploring in the field.\n",
      "\n",
      "Emerging Trends:\n",
      "1. **Interdisciplinary Approaches**: With the increasing complexity of data and problems in machine learning and statistics, there is a growing trend towards interdisciplinary research that combines ideas from computer science, statistics, mathematics, and domain-specific knowledge. Researchers can explore how combining these diverse fields can lead to breakthroughs in addressing real-world challenges.\n",
      "\n",
      "2. **Deep Learning Interpretability**: As deep learning models gain popularity for their high predictive performance, there is a rising need for interpretable models. Exploring methodologies to interpret and explain deep learning models could provide insights into their decision-making processes and enhance trust in their predictions.\n",
      "\n",
      "3. **Fairness and Bias in Machine Learning**: Addressing issues of fairness, bias, and ethics in machine learning algorithms is crucial. Research focusing on developing fair and unbiased machine learning models, as well as methodologies to detect and mitigate biases, can have a significant impact on responsible AI development.\n",
      "\n",
      "Gaps in the Literature:\n",
      "1. **Scalability of Bayesian Methods**: While Bayesian methods offer powerful tools for probabilistic modeling, there is a gap in scalable Bayesian inference techniques for large-scale datasets. Research that devises scalable algorithms for Bayesian modeling, enabling their application to big data problems, is a promising direction.\n",
      "\n",
      "2. **Combining Symbolic AI with Machine Learning**: Integrating symbolic AI, which focuses on logical reasoning and knowledge representation, with modern machine learning techniques could lead to more robust and explainable AI systems. Exploring approaches to combine symbolic reasoning with deep learning for enhanced performance and interpretability is a gap worth addressing.\n",
      "\n",
      "Novel Research Directions:\n",
      "1. **Meta-Learning for Adaptive Algorithms**: Investigating meta-learning techniques to build adaptive machine learning algorithms that can automatically adjust their behavior based on data characteristics or changing environments could lead to more flexible and efficient models.\n",
      "\n",
      "2. **Causal Inference in Machine Learning**: Advancing research at the intersection of causal inference and machine learning can enable the development of models that not only predict outcomes but also understand the causal mechanisms driving them. Exploring causal reasoning within machine learning algorithms could lead to more reliable and actionable insights.\n",
      "\n",
      "3. **Privacy-Preserving Machine Learning**: With increasing concerns about data privacy, developing techniques for privacy-preserving machine learning that allow model training on sensitive data without compromising individual privacy is a promising research direction. Exploring differential privacy, federated learning, and secure multi-party computation could pave the way for more privacy-conscious AI systems.\n",
      "\n",
      "In conclusion, by considering these emerging trends, gaps in the literature, and novel research directions, researchers can contribute towards advancing the field of machine learning and statistics, building on the foundational work of researchers like John Lafferty.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    user_query = input(\"Enter your search query: \")\n",
    "    print(\"Converting your query into an arXiv-friendly format...\")\n",
    "    arxiv_query = enhance_query(user_query)\n",
    "    print(f\"Here is the arXiv Query I am using: {arxiv_query}\\nFetching papers from arXiv...\")\n",
    "    arxiv_results = search_arxiv(arxiv_query)\n",
    "    extracted_information = extract_titles_and_summaries(arxiv_results)\n",
    "    # print(extracted_information)\n",
    "    thoughtful_response = summarize(user_query, extracted_information)\n",
    "    print(\"Here's what I found:\\n\", thoughtful_response)\n",
    "    research_suggestions = suggest_research_directions(user_query, thoughtful_response)\n",
    "    print(\"Here are a few research ideas to inspire your work:\\n\", research_suggestions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da28b92-ae40-41df-9846-b46017f4e777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
